# 神经网络入门



(1)sigmoid函数(处处可导)
(2)tanh函数(处处可导)
(3)ReLU函数(综合性能优良，普适性较高，目前最为常用的激励函数)

<img src="neuralNetwork_img/image-20210829225219989.png" alt="image-20210829225219989" style="zoom: 67%;" />







